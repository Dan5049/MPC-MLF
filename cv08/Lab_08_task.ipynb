{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM/13tWUp5U57YqkJdxftyv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dan5049/MPC-MLF/blob/main/cv08/Lab_08_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wNomXe5J2mV"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop #RootMeanSquare error\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O kafka_Metamorphosis.txt https://www.gutenberg.org/files/5200/5200-0.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97ursKUzKamc",
        "outputId": "ce3c251d-144e-43c5-d4ee-46af8d531626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-06 07:19:10--  https://www.gutenberg.org/files/5200/5200-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 142017 (139K) [text/plain]\n",
            "Saving to: ‘kafka_Metamorphosis.txt’\n",
            "\n",
            "kafka_Metamorphosis 100%[===================>] 138.69K   205KB/s    in 0.7s    \n",
            "\n",
            "2023-04-06 07:19:12 (205 KB/s) - ‘kafka_Metamorphosis.txt’ saved [142017/142017]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open('kafka_Metamorphosis.txt', 'r').read().lower()\n",
        "print('test length: ', len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2rLr-jJLFHz",
        "outputId": "dfebb5e6-f358-461e-eabf-f48d1b8e8260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test length:  138408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK_mcoCJLsFj",
        "outputId": "442ad159-1363-4b9a-c396-146448c672ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿the project gutenberg ebook of metamorphosis, by franz kafka\n",
            "\n",
            "this ebook is for the use of anyone anywhere in the united states and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever. you may copy it, give it away or re-use it under the terms\n",
            "of the project gutenberg license included with this ebook or online at\n",
            "www.gutenberg.org. if you are not located in the united states, you\n",
            "will have to check the laws of the country where you are located before\n",
            "using this ebook.\n",
            "\n",
            "** this is a copyrighted project gutenberg ebook, details below **\n",
            "**     please follow the copyright guidelines in this file.     **\n",
            "\n",
            "title: metamorphosis\n",
            "\n",
            "author: franz kafka\n",
            "\n",
            "translator: david wyllie\n",
            "\n",
            "release date: may 13, 2002 [ebook #5200]\n",
            "[most recently updated: may 20, 2012]\n",
            "\n",
            "language: english\n",
            "\n",
            "character set encoding: utf-8\n",
            "\n",
            "copyright (c) 2002 by david wyllie.\n",
            "\n",
            "*** start of the project gutenberg ebook metamorphosis ***\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "metamorphosis\n",
            "\n",
            "by franz kafka\n",
            "\n",
            "translated by david wyllie\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('total chars: ', len(chars))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBEWGEPKMyMh",
        "outputId": "cc1f7913-648d-4b9e-dd41-589f5bd531f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total chars:  62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indicies_chars = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "cg5VdnUcNNmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "  sentences.append(text[i: i + maxlen])\n",
        "  next_chars.append(text[i + maxlen])\n",
        "\n",
        "print('nb sentences: ', len(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlyBCWybNhdb",
        "outputId": "9a51aecc-8d23-4ee3-ffa5-7b484069ecff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb sentences:  46123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[:3])\n",
        "print(next_chars[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bec4GrETOUn7",
        "outputId": "5f4ad078-484f-4902-a45c-b30e6b6ca621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\ufeffthe project gutenberg ebook of metamorp', 'e project gutenberg ebook of metamorphos', 'roject gutenberg ebook of metamorphosis,']\n",
            "['h', 'i', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GALRX7TSOlHx",
        "outputId": "d9088ebd-b745-409c-cd17-1cbd88c7c1cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-8b86d899b220>:1: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
            "<ipython-input-45-8b86d899b220>:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[:3])\n",
        "print(y[:3])\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkaWmguyPmZs",
        "outputId": "d6db5a1d-b81c-4d10-e68d-6da6aa4b1471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[False False False ... False False  True]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False  True False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]]\n",
            "[[False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False  True False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False  True False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False]\n",
            " [False  True False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False]]\n",
            "(46123, 40, 62)\n",
            "(46123, 62)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(254, input_shape = (maxlen, len(chars))))\n",
        "model.add(Dense(10*len(chars)))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "ZJ9xtu_8P9TB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr = 0.01))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n53yk_hKQn4F",
        "outputId": "1d867048-4001-43a2-a775-ead27a0ae74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size = 128, epochs = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBznhUpARpHt",
        "outputId": "2583b8a4-6d37-4b3b-c268-ef2945c1c447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "361/361 [==============================] - 5s 8ms/step - loss: 3.1079\n",
            "Epoch 2/10\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 1.9103\n",
            "Epoch 3/10\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 1.6925\n",
            "Epoch 4/10\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 1.5420\n",
            "Epoch 5/10\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 1.4206\n",
            "Epoch 6/10\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 1.3137\n",
            "Epoch 7/10\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 1.2207\n",
            "Epoch 8/10\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 1.1321\n",
            "Epoch 9/10\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 1.0430\n",
            "Epoch 10/10\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.9736\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f334eebea60>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature = 1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def generate_text(sentence, length, diversity):\n",
        "  generated = ''\n",
        "  generated += sentence\n",
        "  for i in range(length):\n",
        "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(sentence):\n",
        "      x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "    preds = model.predict(x_pred, verbose = 0)[0]\n",
        "    next_index = sample(preds, diversity)\n",
        "    next_char = indicies_chars[next_index]\n",
        "\n",
        "    generated += next_char\n",
        "    sentence = sentence[1:] + next_char\n",
        "  \n",
        "  return generated"
      ],
      "metadata": {
        "id": "swCymbZeYHMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" the first thing he wanted to do was to \"\n",
        "sentence = text[0:maxlen]\n",
        "\n",
        "print(generate_text(sentence, 30, 0.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q9NINvvaGQ9",
        "outputId": "65758b41-6741-4b7c-c95f-81155ef843b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the first thing he wanted to do was to be of the back a look at all p\n"
          ]
        }
      ]
    }
  ]
}